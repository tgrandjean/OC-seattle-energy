%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section{Introduction}

L'objectif de ce travail est de produire un modèle statistique permettant de prévoir
les consommations des bâtiments ainsi que les rejets de gaz à effet de serre (GHG) sur
base des informations du permis d'exploitation.

Une analyse préliminaire des données ainsi que la sélection d'un modèle
adapté sont ici détaillées.
%------------------------------------------------

\section{Données disponibles}

Dans cette section, vous trouverez toutes les informations sur le set de données
utilisé tout au long de ce travail.

\subsection{généralités}

Les données sont disponibles gratuitement sur le site de la ville de seattle et
également sur la plateforme "Kaggle".

Le jeu de données contient deux fichiers :
\begin{itemize}
  \item{2015-building-energy-benchmarking.csv}
  \item{2016-building-energy-benchmarking.csv}
\end{itemize}

Les deux fichiers contiennent essentiellement les mêmes variables mais
certaines (Par exemple : la localisation) sont encodées différemment.

\paragraph{Notes}

Les seules différences notables entre les deux fichiers sont:
\begin{itemize}
  \item{Le jeu de 2016 contient 36 observations de plus que celui de 2015.}
  \item{Les données de 2016 n'ont pas la variable "OtherFuelUse"}
  \item{Les données de 2015 contiennent une variable "Location" contenant les
       informations suivantes}
  \begin{itemize}
    \item{City}
    \item{State}
    \item{ZipCode}
    \item{Address}
    \item{Latitude et longitude}
  \end{itemize}
  \item{Les colonnes suivantes ont été renommées}
  \begin{itemize}
    \item{Comment : comments}
    \item{GHGEmissions(MetricTonsCO2e) : TotalGHGEmissions}
    \item{GHGEmissionsIntensity(kgCO2e/ft2) : GHGEmissionsIntensity}
  \end{itemize}
\end{itemize}

\subsection{Travail préliminaire sur les données}

Les deux jeux de données sont uniformisés au niveau des variables
(la colonne "Location" du jeu de données de 2015 est transformée en colonnes
"Address", "ZipCode", "Latitude", "Longitude", ...) puis aggrégés pour former
un jeu unique contenant 47 variables et 6716 observations.

On a donc les variables suivantes :
  voir table \ref{tab:table-variables}

\begin{table}[p]
  \caption{liste des variables}
  \label{tab:table-variables}
\input{./includes/variables.tex}
\end{table}

\paragraph{Suppression des observations dont la consommation est nulle}
On supprime toutes les lignes pour lesquelles la consommation du bâtiment est $\le$ 0.
Cela concerne 103 lignes sur 6716 soit 1,53 \% des données.
%------------------------------------------------

\section{Analyse exploratoire des données}

Dans cette section, vous trouverez les informations concernant les données en
elles-mêmes. Pour ne pas surcharger inutilement ce document, seules les
variables ayant un intérêt pour la suite sont traitées (Toutes les variables
sont passées au crible dans le notebook \Verb+1.0-tg-initial-data-exploration.ipynb+).

\subsection{Analyse des variables}

\subsubsection{Analyses univariées}

\paragraph{Usage des surfaces} On peut regarder la répartission des différents
usages de surfaces.
\begin{figure}[H]
  \includegraphics[width=\linewidth]{univar_primary_property_type.png}
  \caption{Principaux usages des bâtiments}
  \label{}
\end{figure}

\paragraph{Surface totale des bâtiments} On regarde la distribution des valeurs
de GFA (gross floor area.)
\begin{figure}[H]
  \includegraphics[width=\linewidth]{univar_property_gfa_total.png}
  \caption{Distribution des valeurs "Surface du bâtiment"}
  \label{}
\end{figure}


\subsubsection{Analyses bivariées}

On cherche quelles sont les variables corrélées avec la consommation d'énergie
du bâtiment. Seules les variable ayant un lien avec la consommation d'énergie du
bâtiment sont présentés ici. (Pour une analyse exhaustive, voir \Verb+1.0-tg-initial-data-exploration.ipynb+)

\paragraph{Lien entre la surface du bâtiment et la consommation}

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{bivar_gfa_energy.png}
  \caption{Régression linéaire entre la surface du bâtiment (TotalGFA) et la
  consommation}
  \label{reg_1}
\end{figure}

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{bivar_gfa_energy_log.png}
  \caption{Régression linéaire entre la surface du bâtiment (TotalGFA) et la
  consommation avec passage en log}
  \label{reg_2}
\end{figure}

On observe une corrélation entre les variables. Il vient d'instinct que plus
le bâtiment est grand plus il consomme. Cependant, on remarque que suivant l'usage
l'usage des surfaces du bâtiment, la consommation peut être au-dessus ou en-dessous
de la droite présente sur la figure (voir figure \ref{reg_1} \ref{reg_2}). Ce
dernier point est mis en avant sur la figure \ref{reg_3}

\begin{figure}[H]
  \includegraphics[width=\linewidth]{reg_plot_color.png}
  \caption{Relation entre la surface et la consommation. La couleur des points
  est donnée par le Première usage du bâtiment. Il est fortement conseillé
  de visualiser ce graphique sous forme interactive (voir notebook : \emph{2.0-features-selection.ipynb}}
  \label{reg_3}
\end{figure}
\input{./includes/OLS_res.tex}

De
\paragraph{Lien entre le type d'utilisation et la consommation}
On peut regarder si le type d'utilisation des surfaces impact la consommation du bâtiment.
On réalise donc une analyse de type "ANOVA" \cite{rutherford2001introducing}(analyse de variance) pour déterminer
si l'usage (donnée catégorielle) impact la consommation (ici consommation au mètre carré\footnote{Les données provenant des US, les données sont exprimées dans les unités US (kBtu/sf)}).

\begin{table*}[p]
  \centering
  \caption{Résulats analyse ANOVA}
\begin{tabular}{@{}lllll@{}}
\toprule
sum\_sq                   & df           & F      & PR(\textgreater{}F) &     \\ \midrule
C(LargestUseType) & 5.371104e+17 & 56.0   & 64.957921           & 0.0 \\
Residual                  & 9.531025e+17 & 6455.0 & NaN                 & NaN \\ \bottomrule
\end{tabular}
\end{table*}

La probabilité

On peut ensuite poursuivre l'analyse par
un test des paires HSD de Tukey \cite{abdi2020} (Pour déterminer quel type d'usage impact la moyenne.)

On remarque alors qu'un grand nombre d'usage type n'ont pas d'impact sur la moyenne.


\begin{figure*}
  \includegraphics[width=\linewidth]{ANOVA_1.png}
  \caption{Distribution des consommations normalisées par la surface du bâtiment,
           en fonction du premier usage du bâtiment}
  \label{}
\end{figure*}
\begin{figure*}
  \includegraphics[width=\linewidth]{TukeyHSD_1.png}
  \caption{}
  \label{}
\end{figure*}


\subsubsection{Feature engineering}

Les données sont ré-encodées différemment pour servir d'entrée au modèle

\paragraph{Baseline}
On établit en premier lieu une valeur de référence sur les données originales (données provenant
du fichier \Verb+interim/full_dataV2.pickle+).
On utilise alors les colonnes:
\begin{itemize}
  \item PropertyGFATotal
  \item LargestPropertyUseType
  \item LargestPropertyUseTypeGFA
  \item SecondLargestPropertyUseType
  \item SecondLargestPropertyUseTypeGFA
  \item ThirdLargestPropertyUseType
  \item ThirdLargestPropertyUseTypeGFA
\end{itemize}
comme données d'entrées du modèle et la colonne SiteEnergyUseWN\_kBtu comme cible
du modèle. Les données catégorielles sont encodées en format binaire (voir OneHotEncoding)
et les données numériques (surface en sf) sont alors standardisée (StandardScaler).
On entraine alors une régression linéaire simple (OLS) sur les données.

\noindent Score on training set (2015) : 0.803732\newline
Score on testing set (2016) : 0.694067

\paragraph{Données réencodées}
On calcul alors le gain ou la perte sur les données réencodées.
Dans un premier temps, on transforme les données comme suit:
\begin{enumerate}
  \item OneHotEncoding des données catégorielles
  \item Fusion des données binaires issues du OneHotEncoding
  \item Remplacement des "1" par les valeurs de GFA associées.
\end{enumerate}
On a alors un tableau de données contenant 64 colonnes. (fichier \Verb+processed/model_data.pickle+)
\noindent Score on training set : 0.354263\newline
Score on testing set : 0.302856\newline


Dans un second temps, on retransforme le set précédent de la manière suivante:
\begin{enumerate}
  \item On somme les surfaces ligne par ligne dans une colonne (TotalGFA)
  \item On divise alors les cellules par la surface totale calculée précédement.
  \item On obtient alors des données exprimées en pourcentage de la surface totale.
\end{enumerate}
On a alors un  tableau de données contenant 65 colonnes (64 usages type des surfaces ainsi
que la surface totale.). (fichier \Verb+processed/model_data_percentV2.pickle+)

\noindent Score on training set : 0.809332\newline
Score on testing set : 0.749299

%------------------------------------------------

\section{Modèle}


\subsection{Données d'entrée (input)}

On utilise les données préalablement ré-encodées comme entrée du modèle.
On a donc 65 variables d'entrée pour le modèle (64 usages type des surfaces ainsi
que la surface totale.).
Les 64 premières colonnes sont donc des flotants (float64) compris entre 0 et 1.
La 65\up{ème} colonne contient les surfaces totale (TotalGFA) cette dernière
subit une transformation logarithmique lors de l'entrainement du modèle.

\subsection{Données de sortie (output)}

Dans un premier temps, on se focalise uniquement sur la consommation énergétique
des bâtiments et non sur la production de GES (Les GES sont traités plus loin
dans le document).

\subsection{Sélection du modèle}
La modélisation des données est réalisée à l'aide de la bibliothèque Python Scikit-Learn \cite{scikit-learn}

Pour sélectionner un modèle, on entraîne successivement les modèles de
régression suivant:
\begin{itemize}
  \item LinearRegression (Régression linéaire simple)
  \item Régression linéaire avec régularisation.
  \begin{itemize}
    \item Ridge \cite{Marquardt1975}
    \item Lasso \cite{tibshirani96regression}
    \item ElasticNet
  \end{itemize}
  \item Régression non linéaire.
  \begin{itemize}
    \item Support Vector Machine (support vector regression SVR)
    \item Stochastic gradient descent (SGDRegressor)
    \item Nearest neighbors (KNeighborsRegressor)
    \item Arbres de décision (DecisionTreeRegressor)
  \end{itemize}
  \item Méthode d'ensemble
  \begin{itemize}
    \item RandomForestRegressor
    \item GradientBoostingRegressor
  \end{itemize}
  \item Réseau de neurones artificiels: Multilayer perceptron (MLPRegressor)
\end{itemize}

On peut alors comparer les résultats obtenus sur ces modèles.
\begin{table}[H]
  \input{./includes/scores_1.tex}
  \caption{Scores obtenus avec paramètres par défaut}
  \label{}
\end{table}

Hormis la régression linéaire simple, l'ensemble des modèles utilisés comportent
des hyperparamètres\footnote{On fait la distinction ici entre les paramètres
qui sont optimisés au sein du modèle et les paramètres externe au modèles appelés
hyperparamètres.} à optimiser.
Pour une comparaison des modèles en bon et dû forme, il est possible d'optimiser
les hyperparamètres de manière récursive et de comparer les modèles optimisés.
\footnote{Certain modèle demande un temps calcul non négligeable et prennent donc
du temps à entrainer, à ce stade, les modèles sont donc grossièrement optimisés
pour comparaison.}

\begin{figure}[H]
  \includegraphics[width=\linewidth]{models_scores.png}
  \caption{scores obtenus pour les modèles de régression}
  \label{}
\end{figure}

\begin{table}
  \input{./includes/scores_2.tex}
  \caption{Scores obtenus après une première optimisation des hyperparamètres}
  \label{}

\end{table}

\begin{figure*}[p]
  \includegraphics[width=\linewidth]{all_models_results_test.png}
  \caption{Prédictions vs réalité -- données de test}
  \label{}
\end{figure*}

\subsection{Algorithme sélectionné}

\subsubsection{RandomForestRegressor}

\paragraph{Avantages} Meilleure généralisation
(Le modèle donne des résultats très similaires sur les données d'entrainement et
sur les donnnées de test. ).

\paragraph{Points faibles}

\subsubsection{DecisionTreeRegressor}

\paragraph{Avantages}

\paragraph{Points faibles}

\subsubsection{Modèle retenu}




\subsection{Entrainement du modèle}


%------------------------------------------------

\section{Résultats}


%------------------------------------------------

\section{Conclusion}


%------------------------------------------------
